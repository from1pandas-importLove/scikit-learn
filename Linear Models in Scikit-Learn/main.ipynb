{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "8f69a9514328230e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this lab, we will explore linear models in scikit-learn. Linear models are a set of methods used for regression and classification tasks. They assume that the target variable is a linear combination of the features. These models are widely used in machine learning due to their simplicity and interpretability.\n",
    "\n",
    "We will cover the following topics:\n",
    "\n",
    "- Ordinary Least Squares\n",
    "- Ridge Regression\n",
    "- Lasso\n",
    "- Logistic Regression\n",
    "- Stochastic Gradient Descent\n",
    "- Perceptron"
   ],
   "id": "e9a5edb12587bf1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ordinary Least Squares",
   "id": "9ede27789d479d7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ordinary Least Squares (OLS) is a linear regression method that minimizes the sum of squared differences between the observed targets and the predicted targets. Mathematically, it solves a problem of the form:",
   "id": "6698368f84863c10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start by fitting a linear regression model using OLS.",
   "id": "ec777f989c2cad0d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T21:11:34.452490Z",
     "start_time": "2025-09-07T21:11:33.277456Z"
    }
   },
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "X = [[0, 0], [1, 1], [2, 2]]\n",
    "y = [0, 1, 2]\n",
    "reg.fit(X, y)\n",
    "\n",
    "print(reg.coef_)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ridge Regression",
   "id": "559330ab27fba35b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ridge regression is a linear regression method that adds a penalty term to the ordinary least squares objective function. This penalty term helps to reduce overfitting by shrinking the coefficients towards zero. The complexity of the model can be controlled by the regularization parameter.\n",
    "\n",
    "Let's fit a ridge regression model."
   ],
   "id": "6e8e0d0d83c1b951"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T21:12:16.836210Z",
     "start_time": "2025-09-07T21:12:16.815220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reg = linear_model.Ridge(alpha=0.5)\n",
    "reg.fit([[0, 0], [0, 0], [1, 1]], [0, 0.1, 1])\n",
    "\n",
    "print(reg.coef_)"
   ],
   "id": "3121f4be27cbee9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34545455 0.34545455]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lasso",
   "id": "56bc6880ef17df20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lasso is a linear regression method that adds a penalty term to the ordinary least squares objective function. The penalty term has the effect of setting some coefficients to exactly zero, thus performing feature selection. Lasso can be used for sparse model estimation.\n",
    "\n",
    "Let's fit a lasso model."
   ],
   "id": "3287a2f224302685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T21:13:03.284922Z",
     "start_time": "2025-09-07T21:13:03.267868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reg = linear_model.Lasso(alpha=0.1)\n",
    "reg.fit([[0, 0], [1, 1]], [0, 1])\n",
    "\n",
    "print(reg.coef_)"
   ],
   "id": "46bff6d5a2f522e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 0. ]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Logistic Regression",
   "id": "b7017e548dacc6ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Logistic regression is a classification method that estimates the probabilities of the possible outcomes using a logistic function. It is commonly used for binary classification tasks. Logistic regression can also be extended to handle multi-class classification problems.\n",
    "\n",
    "Let's fit a logistic regression model."
   ],
   "id": "4607f62c6dfe1143"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T21:13:39.834344Z",
     "start_time": "2025-09-07T21:13:39.793555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = linear_model.LogisticRegression(random_state=0).fit(X, y)\n",
    "print(clf.coef_)"
   ],
   "id": "bb340a83854ae9c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.80679547e-01 -4.80679547e-01]\n",
      " [-2.06085772e-05 -2.06085772e-05]\n",
      " [ 4.80700156e-01  4.80700156e-01]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stochastic Gradient Descent (SGD)",
   "id": "72d2dd74809ebd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Stochastic Gradient Descent (SGD) is a simple yet efficient approach for training linear models. It is particularly useful when the number of samples and features is very large. SGD updates the model parameters using a small subset of the training data at each iteration, which makes it suitable for online learning and out-of-core learning.\n",
    "\n",
    "Let's fit a logistic regression model using SGD."
   ],
   "id": "a98c10295489a40f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T21:14:21.566902Z",
     "start_time": "2025-09-07T21:14:21.544993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = linear_model.SGDClassifier(loss=\"log_loss\", max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.coef_)"
   ],
   "id": "2c75d88c6109f630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.22569766  -5.22569766]\n",
      " [-10.09065328 -10.09065328]\n",
      " [  5.178237     5.178237  ]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Perceptron",
   "id": "c92af693c601e257"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Perceptron is a simple linear classification algorithm suitable for large-scale learning. It updates its model only on mistakes, making it faster to train than the stochastic gradient descent (SGD) with hinge loss. The resulting models are also sparser.\n",
    "\n",
    "Let's fit a perceptron model."
   ],
   "id": "ed3fcfa728a47398"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T21:15:01.718778Z",
     "start_time": "2025-09-07T21:15:01.703738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = linear_model.Perceptron(alpha=0.1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.coef_)"
   ],
   "id": "5aa1b11c2a664b81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "c2f9fe984276ed1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this lab, we explored linear models in scikit-learn. We learned about ordinary least squares, ridge regression, lasso, logistic regression, stochastic gradient descent, and perceptron. These models can be used for both regression and classification tasks. We also saw how to fit these models using various algorithms and techniques such as online learning and feature selection.",
   "id": "2fe56e5dfbfbc932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1cbb4e697dab92d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
