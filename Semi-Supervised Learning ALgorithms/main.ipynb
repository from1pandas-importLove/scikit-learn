{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "2bc4ffd64f1639b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this lab, we will explore the concept of semi-supervised learning, which is a type of machine learning where some of the training data is labeled and some is unlabeled. Semi-supervised learning algorithms can leverage the unlabeled data to improve the model's performance and generalize better to new samples. This is particularly useful when we have a small amount of labeled data but a large amount of unlabeled data.\n",
    "\n",
    "In this lab, we will focus on two semi-supervised learning algorithms: Self Training and Label Propagation. We will learn how to implement and use these algorithms using scikit-learn, a popular machine learning library in Python."
   ],
   "id": "fad9ed5ab8e6d01e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Self Training",
   "id": "f6c518654eaab07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Overview of Self Training algorithm",
   "id": "2c91da60e2126c0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Self Training algorithm is based on Yarowsky's algorithm. It allows a supervised classifier to function as a semi-supervised classifier by learning from unlabeled data. The algorithm works by iteratively training the supervised classifier on both the labeled and unlabeled data, and then using the predictions on the unlabeled data to add a subset of these samples to the labeled data. The algorithm continues iterating until all the samples have labels or no new samples are selected in an iteration.",
   "id": "7635f36586d6bef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using Self Training in scikit-learn",
   "id": "c70dfc0240c3b943"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In scikit-learn, the Self Training algorithm is implemented in the **SelfTrainingClassifier** class. To use this algorithm, you need to provide a supervised classifier that implements the **predict_proba** method. Here's an example of how to use the Self Training algorithm:",
   "id": "38a0f494e0e0aeee"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-04T16:07:48.968505Z",
     "start_time": "2025-10-04T16:07:44.362463Z"
    }
   },
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create a self-training classifier with the logistic regression classifier as the base classifier\n",
    "self_training_classifier = SelfTrainingClassifier(classifier)\n",
    "\n",
    "# Train the self-training classifier on the labeled and unlabeled data\n",
    "self_training_classifier.fit(X_labeled, y_labeled, X_unlabeled)\n",
    "\n",
    "# Predict the labels for new samples\n",
    "y_pred = self_training_classifier.predict(X_test)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_labeled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      8\u001B[39m self_training_classifier = SelfTrainingClassifier(classifier)\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m# Train the self-training classifier on the labeled and unlabeled data\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m self_training_classifier.fit(\u001B[43mX_labeled\u001B[49m, y_labeled, X_unlabeled)\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# Predict the labels for new samples\u001B[39;00m\n\u001B[32m     14\u001B[39m y_pred = self_training_classifier.predict(X_test)\n",
      "\u001B[31mNameError\u001B[39m: name 'X_labeled' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the example above, **X_labeled** and **y_labeled** are the labeled data, **X_unlabeled** is the unlabeled data, and **X_test** is the new samples to be predicted.",
   "id": "fe786d5dba1e7055"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Label Propagation",
   "id": "fed94e966be01321"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Overview of Label Propagation algorithm",
   "id": "8ae39dedf321efdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Label Propagation is a type of semi-supervised graph inference algorithm. It constructs a similarity graph over all items in the input dataset and uses this graph to propagate the labels from the labeled data to the unlabeled data. Label Propagation can be used for classification tasks and supports kernel methods to project the data into alternate dimensional spaces.",
   "id": "73d92cbfc4dee126"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Label Propagation in scikit-learn",
   "id": "84653bfb6cfaf771"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In scikit-learn, there are two label propagation models available: **LabelPropagation** and **LabelSpreading**. Both models construct a similarity graph and propagate the labels. Here's an example of how to use Label Propagation:",
   "id": "720a2e23639b78b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "# Create a label propagation model\n",
    "label_propagation = LabelPropagation()\n",
    "\n",
    "# Train the label propagation model on the labeled data\n",
    "label_propagation.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Predict the labels for new samples\n",
    "y_pred = label_propagation.predict(X_test)"
   ],
   "id": "97428d3f3d7e2c06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the example above, **X_labeled** and **y_labeled** are the labeled data, and **X_test** is the new samples to be predicted.",
   "id": "c05d0f1f3fe85614"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "68aad476eead501e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Semi-supervised learning is a powerful technique that allows us to leverage unlabeled data to improve the performance of our models. In this lab, we learned about two semi-supervised learning algorithms: Self Training and Label Propagation. We also learned how to implement and use these algorithms using scikit-learn. By incorporating unlabeled data into our machine learning workflows, we can make better use of the available data and achieve more accurate predictions.",
   "id": "c72a66251913409f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c3c58890b9e28421"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
