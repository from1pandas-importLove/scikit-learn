{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "a0173cc049bb2f7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Feature selection is an important step in machine learning. It involves selecting the most relevant features from a dataset to improve the accuracy and performance of the model. In scikit-learn, the **sklearn.feature_selection** module provides various methods for feature selection and dimensionality reduction.\n",
    "\n",
    "This lab will guide you through the process of feature selection using scikit-learn. We will cover techniques such as removing features with low variance, univariate feature selection, recursive feature elimination, and feature selection using SelectFromModel."
   ],
   "id": "769468f6d35d5ca9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing features with low variance",
   "id": "32f655882d6255eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The **VarianceThreshold** class in scikit-learn can be used to remove features with low variance. Features with low variance typically do not provide much information for the model. We will demonstrate how to use **VarianceThreshold** to remove zero-variance features.",
   "id": "2223f53ebcf9a9ce"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-05T11:58:50.585409Z",
     "start_time": "2025-07-05T11:58:50.576675Z"
    }
   },
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]])\n",
    "\n",
    "# Initialize VarianceThreshold with a threshold of 80% variability\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "\n",
    "# Select features with high variability\n",
    "X_selected = sel.fit_transform(X)\n",
    "\n",
    "print(\"Original X shape:\", X.shape)\n",
    "print(\"X with selected features shape:\", X_selected.shape)\n",
    "print(\"Selected features:\", sel.get_support(indices=True))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (6, 3)\n",
      "X with selected features shape: (6, 2)\n",
      "Selected features: [1 2]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code snippet demonstrates how to use **VarianceThreshold** to remove zero-variance features from a dataset. The output will show the original shape of the dataset and the shape after selecting features with high variability.",
   "id": "1a3453f4e77fe608"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Univariate feature selection",
   "id": "e597e7e23475fa6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. In scikit-learn, there are several classes that implement univariate feature selection:\n",
    "\n",
    "- **SelectKBest**: selects the top k highest scoring features\n",
    "- **SelectPercentile**: selects a user-specified percentage of highest scoring features\n",
    "- **SelectFpr**: selects features based on the false positive rate\n",
    "- **SelectFdr**: selects features based on the false discovery rate\n",
    "- **SelectFwe**: selects features based on family wise error\n",
    "- **GenericUnivariateSelect**: allows selection with a configurable strategy\n",
    "\n",
    "Here is an example of using **SelectKBest** to select the two best features from the Iris dataset:"
   ],
   "id": "d5920e803e3c00bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T12:07:13.272158Z",
     "start_time": "2025-07-05T12:07:13.146713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize SelectKBest with the f_classif scoring function and k=2\n",
    "selector = SelectKBest(f_classif, k=2)\n",
    "\n",
    "# Select the best features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Original X shape:\", X.shape)\n",
    "print(\"X with selected features shape:\", X_selected.shape)\n",
    "print(\"Selected features:\", selector.get_support(indices=True))\n"
   ],
   "id": "410566f465106a34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (150, 4)\n",
      "X with selected features shape: (150, 2)\n",
      "Selected features: [2 3]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this example, we use the **f_classif** scoring function and select the two best features from the Iris dataset. The output will show the original shape of the dataset and the shape after selecting the best features.",
   "id": "b4a69718d36719cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Recursive feature elimination",
   "id": "f72d7a4dc097a8a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Recursive feature elimination (RFE) is a feature selection method that recursively considers smaller and smaller sets of features to select the most important ones. It works by training an external estimator with weights assigned to features and pruning the least important features.",
   "id": "55fda0aeb8d8e772"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T12:08:28.740187Z",
     "start_time": "2025-07-05T12:08:28.713743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize SVC as the external estimator\n",
    "estimator = SVC(kernel=\"linear\")\n",
    "\n",
    "# Initialize RFE with the external estimator and select 2 features\n",
    "selector = RFE(estimator, n_features_to_select=2)\n",
    "\n",
    "# Select the best features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Original X shape:\", X.shape)\n",
    "print(\"X with selected features shape:\", X_selected.shape)\n",
    "print(\"Selected features:\", selector.get_support(indices=True))"
   ],
   "id": "63eec9777f5304cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (150, 4)\n",
      "X with selected features shape: (150, 2)\n",
      "Selected features: [2 3]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this example, we use a Support Vector Classifier (SVC) as the external estimator and select the two best features from the Iris dataset. The output will show the original shape of the dataset and the shape after selecting the best features.",
   "id": "3fbfc681ffb22949"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature selection using SelectFromModel",
   "id": "90a81cf1647c2448"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The **SelectFromModel** class is a meta-transformer that can be used with any estimator that assigns importance to each feature. It selects features based on their importance and removes features below a specified threshold.",
   "id": "4ef4ffa9af3ec182"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T12:09:41.361031Z",
     "start_time": "2025-07-05T12:09:40.927072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize RandomForestClassifier as the estimator\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Initialize SelectFromModel with the estimator and threshold of \"mean\"\n",
    "selector = SelectFromModel(estimator, threshold=\"mean\")\n",
    "\n",
    "# Select the best features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Original X shape:\", X.shape)\n",
    "print(\"X with selected features shape:\", X_selected.shape)\n",
    "print(\"Selected features:\", selector.get_support(indices=True))"
   ],
   "id": "d422857074073b9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (150, 4)\n",
      "X with selected features shape: (150, 2)\n",
      "Selected features: [2 3]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this example, we use a Random Forest Classifier as the estimator and select features with an importance greater than the mean importance. The output will show the original shape of the dataset and the shape after selecting the best features.",
   "id": "963286f9b3f07651"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "cb811591cd4b4c42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature selection is an essential step in machine learning to improve the accuracy and performance of models. In this lab, we covered various techniques such as removing features with low variance, univariate feature selection, recursive feature elimination, and feature selection using SelectFromModel. These techniques help in selecting the most relevant features and reducing the dimensionality of the dataset, resulting in improved model performance.",
   "id": "757193970515d366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3cfc8b62a2e86a6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
