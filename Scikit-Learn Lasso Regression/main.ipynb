{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "2a5039057fb17e71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This lab demonstrates the use of Scikit-learn's Lasso regression algorithm on dense and sparse data. The Lasso algorithm is a linear regression method that adds a penalty to the regression coefficients. This penalty encourages the model to produce sparse coefficients. The Lasso algorithm is useful in situations where the number of features is large compared to the number of samples.",
   "id": "29bee09280d1ff8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Libraries",
   "id": "b58a34e0978af330"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We begin by importing the necessary libraries. We need Scikit-learn, NumPy, and SciPy.",
   "id": "27706d07c2899f44"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-27T21:01:05.234587Z",
     "start_time": "2025-09-27T21:01:02.989781Z"
    }
   },
   "source": [
    "from time import time\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import sparse\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate Dense Data",
   "id": "3286ba31775ad0e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we generate some dense data that we will use for the Lasso regression. We use Scikit-learn's **make_regression** function to generate 200 samples with 5000 features.",
   "id": "e5321d2ef01db42b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:07:50.553925Z",
     "start_time": "2025-09-27T21:07:50.326947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = make_regression(n_samples=200, n_features=5000, random_state=0)\n",
    "X_sp = sparse.csr_matrix(X)  # convert dense numpy array to sparse CSR matrix"
   ],
   "id": "fca16aec701b193b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Lasso on Dense Data",
   "id": "cf9fd7c7fc160ece"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we train two Lasso regression models, one on the dense data and one on the sparse data. We set the alpha parameter to 1 and the maximum number of iterations to 1000.",
   "id": "1e7e96c3076ca45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:07:52.142007Z",
     "start_time": "2025-09-27T21:07:52.135702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alpha = 1\n",
    "sparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\n",
    "dense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)"
   ],
   "id": "732f0949f3e89df4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fit Lasso to Dense Data",
   "id": "e112c900ff737765"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We fit the Lasso regression models to the dense data using Scikit-learn's **fit** function. We also time the fitting process and print the time for each Lasso model.",
   "id": "b166f806ced8bc55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:07:53.243790Z",
     "start_time": "2025-09-27T21:07:53.115587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t0 = time()\n",
    "\n",
    "sparse_lasso.fit(X_sp, y)\n",
    "print(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n",
    "\n",
    "t0 = time()\n",
    "dense_lasso.fit(X, y)\n",
    "print(f\"Dense Lasso done in {(time() - t0):.3f}s\")"
   ],
   "id": "c18660e8017adf76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Lasso done in 0.100s\n",
      "Dense Lasso done in 0.025s\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare Coefficients of Dense Lasso and Sparse Lasso",
   "id": "cc0a85770a1bce42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We compare the coefficients of the dense Lasso model and the sparse Lasso model to ensure that they are producing the same results. We compute the Euclidean norm of the difference between the coefficients.",
   "id": "178c38fbe4c72905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:08:50.024174Z",
     "start_time": "2025-09-27T21:08:49.979617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\n",
    "print(f\"Distance between coefficients : {coeff_diff:.2e}\")"
   ],
   "id": "38c1fd5fc6f90a10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between coefficients : 1.35e-13\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate Sparse Data",
   "id": "c696c89544dac0b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we generate some sparse data that we will use for the Lasso regression. We copy the dense data from the previous step and replace all values less than 2.5 with 0. We also convert the sparse data to Scipy's Compressed Sparse Column format.",
   "id": "f5545877caaa1db2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:09:29.278295Z",
     "start_time": "2025-09-27T21:09:29.237233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xs = X.copy()\n",
    "Xs[Xs < 2.5] = 0.0\n",
    "Xs_sp = sparse.coo_matrix(Xs)\n",
    "Xs_sp = Xs_sp.tocsc()"
   ],
   "id": "9b9f821ed8ab9a78",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Lasso on Sparse Data",
   "id": "10850f5183117aae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we train two Lasso regression models, one on the dense data and one on the sparse data. We set the alpha parameter to 0.1 and the maximum number of iterations to 10000.",
   "id": "d9d523b21fcedbc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:09:57.969237Z",
     "start_time": "2025-09-27T21:09:57.958418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alpha = 0.1\n",
    "sparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "dense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)"
   ],
   "id": "78cfc43859c0022f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fit Lasso to Sparse Data",
   "id": "37b9839fc6ebfd51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We fit the Lasso regression models to the sparse data using Scikit-learn's **fit** function. We also time the fitting process and print the time for each Lasso model.",
   "id": "e1882f4a9d1e6d59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:10:27.636282Z",
     "start_time": "2025-09-27T21:10:27.191140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t0 = time()\n",
    "sparse_lasso.fit(Xs_sp, y)\n",
    "print(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n",
    "\n",
    "t0 = time()\n",
    "dense_lasso.fit(Xs, y)\n",
    "print(f\"Dense Lasso done in  {(time() - t0):.3f}s\")"
   ],
   "id": "d88c55a56e54d080",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Lasso done in 0.066s\n",
      "Dense Lasso done in  0.367s\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare Coefficients of Dense Lasso and Sparse Lasso",
   "id": "77023f8e349b426b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We compare the coefficients of the dense Lasso model and the sparse Lasso model to ensure that they are producing the same results. We compute the Euclidean norm of the difference between the coefficients.",
   "id": "a9b2aa80a0743045"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:10:59.531535Z",
     "start_time": "2025-09-27T21:10:59.519955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\n",
    "print(f\"Distance between coefficients : {coeff_diff:.2e}\")"
   ],
   "id": "e313ab2b275e0f54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between coefficients : 9.35e-12\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "f8f25a56b24e95cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this lab, we demonstrated the use of Scikit-learn's Lasso regression algorithm on dense and sparse data. We showed that the Lasso algorithm provides the same results for dense and sparse data, and that in the case of sparse data, the algorithm is faster.",
   "id": "65aa3ff3bd6a4352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "44ac8614757ff511"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
