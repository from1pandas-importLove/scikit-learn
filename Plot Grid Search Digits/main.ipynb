{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "fc9ddecea4dd383d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This lab shows how to perform hyperparameter tuning with cross-validation using the scikit-learn library. The aim is to classify handwritten digits images using a binary classification for easier understanding: identifying whether a digit is 8 or not. The dataset used is the digits dataset. The performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step.",
   "id": "7f4b0c24c7d7bbf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "2239fe1dd7719f13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will load the digits dataset and flatten the images to vectors. Each image of 8 by 8 pixels needs to be transformed to a vector of 64 pixels. Thus, we will get a final data array of shape **(n_images, n_pixels)**. We will also split the data into a training and a testing set of equal size.",
   "id": "33ae47f4a8f8985c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-26T07:49:12.199251Z",
     "start_time": "2025-09-26T07:49:10.921089Z"
    }
   },
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target == 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Grid-Search Strategy",
   "id": "571aa5f7c35d3bfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will define a function to be passed to the **refit** parameter of the **GridSearchCV** instance. It will implement the custom strategy to select the best candidate from the **cv_results_** attribute of the **GridSearchCV**. Once the candidate is selected, it is automatically refitted by the **GridSearchCV** instance.\n",
    "\n",
    "Here, the strategy is to short-list the models which are the best in terms of precision and recall. From the selected models, we finally select the fastest model at predicting. Notice that these custom choices are completely arbitrary."
   ],
   "id": "957beab48a2a1e54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T09:10:27.937766Z",
     "start_time": "2025-09-26T09:10:27.841250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def print_dataframe(filtered_cv_results):\n",
    "    \"\"\"Pretty print for filtered dataframe\"\"\"\n",
    "    for mean_precision, std_precision, mean_recall, std_recall, params in zip(\n",
    "        filtered_cv_results[\"mean_test_precision\"],\n",
    "        filtered_cv_results[\"std_test_precision\"],\n",
    "        filtered_cv_results[\"mean_test_recall\"],\n",
    "        filtered_cv_results[\"std_test_recall\"],\n",
    "        filtered_cv_results[\"params\"],\n",
    "    ):\n",
    "        print(\n",
    "            f\"precision: {mean_precision:0.3f} (±{std_precision:0.03f}),\"\n",
    "            f\" recall: {mean_recall:0.3f} (±{std_recall:0.03f}),\"\n",
    "            f\" for {params}\"\n",
    "        )\n",
    "    print()\n",
    "\n",
    "\n",
    "def refit_strategy(cv_results):\n",
    "    \"\"\"Define the strategy to select the best estimator.\n",
    "\n",
    "    The strategy defined here is to filter-out all results below a precision threshold\n",
    "    of 0.98, rank the remaining by recall and keep all models with one standard\n",
    "    deviation of the best by recall. Once these models are selected, we can select the\n",
    "    fastest model to predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy (masked) ndarrays\n",
    "        CV results as returned by the `GridSearchCV`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_index : int\n",
    "        The index of the best estimator as it appears in `cv_results`.\n",
    "    \"\"\"\n",
    "    # print the info about the grid-search for the different scores\n",
    "    precision_threshold = 0.98\n",
    "\n",
    "    cv_results_ = pd.DataFrame(cv_results)\n",
    "    print(\"All grid-search results:\")\n",
    "    print_dataframe(cv_results_)\n",
    "\n",
    "    # Filter-out all results below the threshold\n",
    "    high_precision_cv_results = cv_results_[\n",
    "        cv_results_[\"mean_test_precision\"] > precision_threshold\n",
    "    ]\n",
    "\n",
    "    print(f\"Models with a precision higher than {precision_threshold}:\")\n",
    "    print_dataframe(high_precision_cv_results)\n",
    "\n",
    "    high_precision_cv_results = high_precision_cv_results[\n",
    "        [\n",
    "            \"mean_score_time\",\n",
    "            \"mean_test_recall\",\n",
    "            \"std_test_recall\",\n",
    "            \"mean_test_precision\",\n",
    "            \"std_test_precision\",\n",
    "            \"rank_test_recall\",\n",
    "            \"rank_test_precision\",\n",
    "            \"params\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Select the most performant models in terms of recall\n",
    "    # (within 1 sigma from the best)\n",
    "    best_recall_std = high_precision_cv_results[\"mean_test_recall\"].std()\n",
    "    best_recall = high_precision_cv_results[\"mean_test_recall\"].max()\n",
    "    best_recall_threshold = best_recall - best_recall_std\n",
    "\n",
    "    high_recall_cv_results = high_precision_cv_results[\n",
    "        high_precision_cv_results[\"mean_test_recall\"] > best_recall_threshold\n",
    "    ]\n",
    "    print(\n",
    "        \"Out of the previously selected high precision models, we keep all the\\n\"\n",
    "        \"the models within one standard deviation of the highest recall model:\"\n",
    "    )\n",
    "    print_dataframe(high_recall_cv_results)\n",
    "\n",
    "    # From the best candidates, select the fastest model to predict\n",
    "    fastest_top_recall_high_precision_index = high_recall_cv_results[\n",
    "        \"mean_score_time\"\n",
    "    ].idxmin()\n",
    "\n",
    "    print(\n",
    "        \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n",
    "        \"selected subset of best models based on precision and recall.\\n\"\n",
    "        \"Its scoring time is:\\n\\n\"\n",
    "        f\"{high_recall_cv_results.loc[fastest_top_recall_high_precision_index]}\"\n",
    "    )\n",
    "\n",
    "    return fastest_top_recall_high_precision_index"
   ],
   "id": "3370aafb0c78a7ba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Hyperparameters",
   "id": "d6c6eab259380478"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will define the hyperparameters and create the **GridSearchCV** instance.",
   "id": "8d21fe345d479b6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T09:11:15.627404Z",
     "start_time": "2025-09-26T09:11:15.333893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(), tuned_parameters, scoring=[\"precision\", \"recall\"], refit=refit_strategy\n",
    ")"
   ],
   "id": "57d5eb1cd108e759",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fit the Model and Make Predictions",
   "id": "e4fb49f5baa818d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will fit the model and make predictions on the evaluation set.",
   "id": "dbfb6376bee742c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T09:11:41.845576Z",
     "start_time": "2025-09-26T09:11:38.285634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# The parameters selected by the grid-search with our custom strategy are:\n",
    "grid_search.best_params_\n",
    "\n",
    "# Finally, we evaluate the fine-tuned model on the left-out evaluation set: the\n",
    "# `grid_search` object **has automatically been refit** on the full training\n",
    "# set with the parameters selected by our custom refit strategy.\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "c364a7c4afd3c165",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All grid-search results:\n",
      "precision: 1.000 (±0.000), recall: 0.854 (±0.063), for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.257 (±0.061), for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 0.968 (±0.039), recall: 0.780 (±0.083), for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 0.905 (±0.058), recall: 0.889 (±0.074), for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 0.904 (±0.058), recall: 0.890 (±0.073), for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "precision: 0.695 (±0.073), recall: 0.743 (±0.065), for {'C': 1, 'kernel': 'linear'}\n",
      "precision: 0.643 (±0.066), recall: 0.757 (±0.066), for {'C': 10, 'kernel': 'linear'}\n",
      "precision: 0.611 (±0.028), recall: 0.744 (±0.044), for {'C': 100, 'kernel': 'linear'}\n",
      "precision: 0.618 (±0.039), recall: 0.744 (±0.044), for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Models with a precision higher than 0.98:\n",
      "precision: 1.000 (±0.000), recall: 0.854 (±0.063), for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.257 (±0.061), for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Out of the previously selected high precision models, we keep all the\n",
      "the models within one standard deviation of the highest recall model:\n",
      "precision: 1.000 (±0.000), recall: 0.854 (±0.063), for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "precision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "The selected final model is the fastest to predict out of the previously\n",
      "selected subset of best models based on precision and recall.\n",
      "Its scoring time is:\n",
      "\n",
      "mean_score_time                                           0.002244\n",
      "mean_test_recall                                          0.877206\n",
      "std_test_recall                                           0.069196\n",
      "mean_test_precision                                            1.0\n",
      "std_test_precision                                             0.0\n",
      "rank_test_recall                                                 3\n",
      "rank_test_precision                                              1\n",
      "params                 {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Name: 4, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99       807\n",
      "        True       1.00      0.87      0.93        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.93      0.96       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "f3a3bdaa718ca356"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this lab, we learned how to perform hyperparameter tuning with cross-validation using the scikit-learn library. We used the digits dataset and defined a custom refit strategy to select the best candidate from the **cv_results_** attribute of the **GridSearchCV** instance. Finally, we evaluated the fine-tuned model on the left-out evaluation set.",
   "id": "2d8fea8ac3e913f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c135192cfa54292c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
