{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "4fd3b79565223944"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this lab, you will learn how to perform semi-supervised classification on a text dataset using scikit-learn. Semi-supervised learning is a type of machine learning where a model is trained on both labeled and unlabeled data. This lab will cover how to use Self-Training and LabelSpreading algorithms for semi-supervised text classification. We will be using the 20 newsgroups dataset to train and test our models.",
   "id": "7e58c088d2b0d979"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the Dataset",
   "id": "8ca9bca9d3d500c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will be using the 20 newsgroups dataset, which contains around 18,000 newsgroup posts on 20 topics. In this step, we will load the dataset and print out some basic information about it.",
   "id": "cc7bd59b90334bf3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T21:13:24.214797Z",
     "start_time": "2025-06-08T21:13:23.077627Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the dataset with the first five categories\n",
    "data = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    categories=[\n",
    "        'alt.atheism',\n",
    "        'comp.graphics',\n",
    "        'comp.os.ms-windows.misc',\n",
    "        'comp.sys.ibm.pc.hardware',\n",
    "        'comp.sys.mac.hardware',\n",
    "    ],\n",
    ")\n",
    "\n",
    "# print out information about the dataset\n",
    "print('%d documents' % len(data.filenames))\n",
    "print('%d categories' % len(data.target_names))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823 documents\n",
      "5 categories\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create the Pipeline for Supervised Learning",
   "id": "635afaebe48cfc95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we will create a pipeline for supervised learning. The pipeline will consist of a CountVectorizer to convert the text data into a matrix of token counts, a TfidfTransformer to apply term frequency-inverse document frequency normalization to the count matrix, and an SGDClassifier to train the model.",
   "id": "bb00daea468e850a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:19:04.055692Z",
     "start_time": "2025-06-08T21:19:04.044362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Parameters for the SGDClassifier\n",
    "sdg_params = dict(alpha=1e-5, penalty=\"l2\", loss=\"log_loss\")\n",
    "\n",
    "# Parameters for the CountVectorizer\n",
    "vectorizer_params = dict(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", SGDClassifier(**sdg_params)),\n",
    "    ]\n",
    ")"
   ],
   "id": "d61e30aa3357d493",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and Evaluate the Supervised Model",
   "id": "1cf683c18bd61f53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we will split the dataset into training and testing sets, and then train and evaluate the supervised model pipeline we created in Step 2.",
   "id": "fb764852c58ba573"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:22:17.828875Z",
     "start_time": "2025-06-08T21:22:17.113605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Train and evaluate the supervised model pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\n",
    "    'Micro-averaged F1 score on test set: %0.3f'\n",
    "    % f1_score(y_test, y_pred, average='micro')\n",
    ")"
   ],
   "id": "3ca7cf40d3c39ab1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-averaged F1 score on test set: 0.907\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create the Pipleline for Self-Training",
   "id": "ba47f9ec8aaffe30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we will create a pipeline for semi-supervised learning using Self-Training. The pipeline will be similar to the supervised pipeline, but we will use the SelfTrainingClassifier instead of the SGDClassifier.",
   "id": "75a77a696a03cddf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:32:07.541593Z",
     "start_time": "2025-06-08T21:32:07.349321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "# Create the Self-Training pipeline\n",
    "st_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True)),\n",
    "    ]\n",
    ")"
   ],
   "id": "f2fb8a20959d9dec",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and Evaluate the Self-Training Model",
   "id": "ef9f2100bbbe4c96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we will use Self-Training on 20% of the labeled data. We will randomly select 20% of the labeled data, train the model on that data, and then use the model to predict labels for the remaining unlabeled data",
   "id": "fa144932babd18cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:37:38.243726Z",
     "start_time": "2025-06-08T21:37:36.993213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select 20% of the training data\n",
    "y_mask = np.random.rand(len(y_train)) < 0.2\n",
    "X_20, y_20 = map(\n",
    "    list, zip(*((x, y) for x, y, m in zip(X_train, y_train, y_mask) if m))\n",
    ")\n",
    "\n",
    "# Set the non-masked subset to be unlabeled\n",
    "y_train[~y_mask] = -1\n",
    "\n",
    "# Train and evaluate the Self-Training pipeline\n",
    "st_pipeline.fit(X_train, y_train)\n",
    "y_pred = st_pipeline.predict(X_test)\n",
    "print(\n",
    "    \"Micro-averaged F1 score on test set: %0.3f\"\n",
    "    % f1_score(y_test, y_pred, average=\"micro\")\n",
    ")"
   ],
   "id": "2886c79d2c9f1a68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of iteration 1, added 1094 new labels.\n",
      "End of iteration 2, added 187 new labels.\n",
      "End of iteration 3, added 66 new labels.\n",
      "End of iteration 4, added 23 new labels.\n",
      "End of iteration 5, added 19 new labels.\n",
      "End of iteration 6, added 7 new labels.\n",
      "End of iteration 7, added 4 new labels.\n",
      "End of iteration 8, added 7 new labels.\n",
      "End of iteration 9, added 6 new labels.\n",
      "End of iteration 10, added 2 new labels.\n",
      "Micro-averaged F1 score on test set: 0.843\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create the Pipeline for LabelSpreading",
   "id": "9478deddd9ead942"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we will create a pipeline for semi-supervised learning using LabelSpreading. The pipeline will be similar to the supervised pipeline, but we will use the LabelSpreading algorithm instead of the SGDClassifier.",
   "id": "58bf30afc2967fb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:40:36.437789Z",
     "start_time": "2025-06-08T21:40:36.425353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Create the LabelSpreading pipeline\n",
    "ls_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        ('toarray', FunctionTransformer(lambda x: x.toarray())),\n",
    "        ('clf', LabelSpreading()),\n",
    "    ]\n",
    ")"
   ],
   "id": "351cf93ad8590019",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and Evaluate the LabelSpreading Model",
   "id": "f602aa4d0db99500"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we will use LabelSpreading on 20% of the labeled data. We will randomly select 20% of the labeled data, train the model on that data, and then use the model to predict labels for the remaining unlabeled data.",
   "id": "41180fabcdc87bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:41:53.710807Z",
     "start_time": "2025-06-08T21:41:52.250096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ls_pipeline.fit(X_train, y_train)\n",
    "y_pred = ls_pipeline.predict(X_test)\n",
    "print(\n",
    "    \"Micro-averaged F1 score on test set: %0.3f\"\n",
    "    % f1_score(y_test, y_pred, average=\"micro\")\n",
    ")"
   ],
   "id": "8f844e97d69993f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-averaged F1 score on test set: 0.680\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "3bc6f1fb8ef1e55d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this lab, we learned how to perform semi-supervised classification on a text dataset using scikit-learn. We used Self-Training and LabelSpreading algorithms to train and test our models. Semi-supervised learning can be useful when there is a limited amount of labeled data available, and it can help improve the performance of a model by incorporating unlabeled data.",
   "id": "95aceacfca43e7aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1f1f22f58a18ebc8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
